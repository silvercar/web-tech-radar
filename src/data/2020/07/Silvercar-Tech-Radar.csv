name,ring,quadrant,isNew,description
Infrastructure as code,Adopt,Techniques,FALSE,"<p>Although <strong>infrastructure as code</strong> is a relatively old technique (we’ve featured it in the Radar in 2011), it has become vitally important in the modern cloud era where the act of setting up infrastructure has become the passing of configuration instructions to a cloud platform. When we say ""as code"" we mean that all the good practices we've learned in the software world should be applied to infrastructure. Using source control, adhering to the <a href=""https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"">DRY principle</a>, modularization, maintainability, and using automated testing and deployment are all critical practices. Those of us with a deep software and infrastructure background need to empathize with and support colleagues who do not. Saying ""treat infrastructure like code"" isn't enough; we need to ensure the hard-won learnings from the software world are also applied consistently throughout the infrastructure realm.</p>"
Micro frontends,Adopt,Techniques,FALSE,"<p>We've seen significant benefits from introducing <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we've also seen many teams create a front-end monolith — a large, entangled browser application that sits on top of the back-end services — largely neutralizing the benefits of microservices. <strong>Micro frontends</strong> have continued to gain in popularity since they were first introduced. We've seen many teams adopt some form of this architecture as a way to manage the complexity of multiple developers and teams contributing to the same user experience. In June of last year, one of the originators of this technique published an <a href=""https://martinfowler.com/articles/micro-frontends.html"">introductory article</a> that serves as a reference for micro frontends. It shows how this style can be implemented using various web programming mechanisms and builds out an example application using <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>. We're confident this style will grow in popularity as larger organizations try to decompose UI development across multiple teams.</p>"
Pipelines as code,Adopt,Techniques,FALSE,"<p>The <strong>pipelines as code</strong> technique emphasizes that the configuration of delivery pipelines that build, test and deploy our applications or infrastructure should be treated as code; they should be placed under source control and modularized in reusable components with automated testing and deployment. As organizations move to decentralized autonomous teams building <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> or <a href=""/radar/techniques/micro-frontends"">micro frontends</a>, the need for engineering practices in managing pipelines as code increases to keep building and deploying software consistent within the organization. This need has given rise to delivery pipeline templates and tooling that enable a standardized way to build and deploy services and applications. Such tools use the <em>declarative delivery pipelines</em> of applications, adopting a pipeline blueprint to execute the underlying tasks for various stages of a delivery lifecycle such as build, test and deployment; and they abstract away implementation details. The ability to build, test and deploy pipelines as code should be one of the evaluation criteria for choosing a CI/CD tool.</p>"
Structured Logging,Adopt,Techniques,TRUE,"Logging structured messages as a json document allows for better tooling, filtering and analysis"
Pragmatic remote pairing,Trial,Techniques,TRUE,"<p>We firmly believe that <a href=""https://martinfowler.com/articles/on-pair-programming.html"">pair programming</a> improves the quality of code, spreads knowledge throughout a team and allows overall faster delivery of software. In a post COVID-19 world, however, many software teams will be distributed or fully remote, and in this situation we recommend <strong>pragmatic remote pairing</strong>: adjusting pairing practices to what's possible given the tools at hand. Consider tools such as <a href=""/radar/tools/visual-studio-live-share"">Visual Studio Live Share</a> for efficient, low-latency collaboration. Only resort to pixel-sharing if both participants reside in relative geographic proximity and have high-bandwidth internet connections. Pair developers who are in similar time zones rather than expecting pairing to work between participants regardless of their location. If pairing isn't working for logistical reasons, fall back to practices such as individual programming augmented via code reviews, pull-request collaboration (but beware <a href=""/radar/techniques/long-lived-branches-with-gitflow"">long-lived branches with Gitflow</a>) or shorter pairing sessions for critical parts of the code. We've engaged in remote pairing for years, and we've found it to be effective if done with a dose of pragmatism.</p>"
Simplest possible feature toggle,Adopt,Techniques,FALSE,"<p>Unfortunately, <a href=""https://martinfowler.com/articles/feature-toggles.html"">feature toggles</a> are less common than we'd like, and quite often we see people mixing up its types and use cases. It's quite common to come across teams that use heavyweight platforms such as <a href=""https://launchdarkly.com/"">LaunchDarkly</a> to implement feature toggles, including release toggles, to benefit from <a href=""https://martinfowler.com/articles/continuousIntegration.html"">Continuous Integration</a>, when all you need are if/else conditionals. Therefore, unless you need A/B testing or <a href=""https://martinfowler.com/bliki/CanaryRelease.html"">canary release</a> or hand over feature release responsibility to business folks, we encourage you to use the <strong>simplest possible feature toggle</strong> instead of unnecessarily complex feature toggle frameworks.</p>"
"Use ""remote native"" processes and approaches",Adopt,Techniques,TRUE,"<p><a href=""https://www.martinfowler.com/articles/remote-or-co-located.html"">Distributed teams come in many shapes and setups</a>; delivery teams in a 100% single-site co-located setup, however, have become the exception for us. Most of our teams are either multisite teams or have at least some team members working off-site. Therefore, <strong>using ""remote native"" processes and approaches</strong> by default can help significantly with the overall team flow and effectiveness. This starts with making sure that everybody has access to the necessary remote systems. Moreover, using tools such as <a href=""/radar/tools/visual-studio-live-share"">Visual Studio Live Share</a>, <a href=""/radar/tools/mural"">MURAL</a> or <a href=""https://gsuite.google.com/products/jamboard/"">Jamboard</a> turn online workshops and remote pairing into routines instead of ineffective exceptions. But ""remote native"" goes beyond a lift-and-shift of co-location practices to the digital world: Embracing more asynchronous communication, even more discipline around decision documentation, and ""everybody always remote"" meetings are other approaches our teams practice by default to optimize for location fluidity.</p>"
Zero trust architecture (ZTA),Trial,Techniques,TRUE,"<p>The technology landscape of organizations today is increasingly more complex with assets — data, functions, infrastructure and users — spread across security boundaries, such as local hosts, multiple cloud providers and a variety of SaaS vendors. This demands a paradigm shift in enterprise security planning and systems architecture, moving from static and slow-changing security policy management, based on trust zones and network configurations, to dynamic, fine-grained security policy enforcement based on temporal access privileges.</p>

<p><strong>Zero trust architecture (ZTA)</strong> is an organization's strategy and journey to implement zero-trust security principles for all of their assets — such as devices, infrastructure, services, data and users — and includes implementing practices such as securing all access and communications regardless of the network location, enforcing policies as code based on the least privilege and as granular as possible, and continuous monitoring and automated mitigation of threats. Our Radar reflects many of the enabling techniques such as <a href=""/radar/techniques/security-policy-as-code"">security policy as code</a>, <a href=""/radar/techniques/sidecars-for-endpoint-security"">sidecars for endpoint security</a> and <a href=""/radar/techniques/beyondcorp"">BeyondCorp</a>. If you're on your journey toward ZTA, refer to the <a href=""https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207-draft2.pdf"">NIST ZTA publication</a> to learn more about principles, enabling technology components and migration patterns as well as Google's publication on <a href=""https://cloud.google.com/security/beyondprod"">BeyondProd</a>.</p>"
Event sourcing,Assess,Techniques,TRUE,"<p><strong><a href=""https://microservices.io/patterns/data/event-sourcing.html"">Event sourcing</a></strong> persists the state of a business entity such an Order or a Customer as a sequence of state-changing events</p>"
Declarative data pipeline definition,Assess,Techniques,TRUE,"<p>Many data pipelines are defined in a large, more or less imperative script written in Python or Scala. The script contains the logic of the individual steps as well as the code chaining the steps together. When faced with a similar situation in Selenium tests, developers discovered the Page Object pattern, and later many behavior-driven development (BDD) frameworks implemented a split between step definitions and their composition. Some teams are now experimenting with bringing the same thinking to data engineering. A separate <strong>declarative data pipeline definition</strong>, maybe written in YAML, contains only the declaration and sequence of steps. It states input and output data sets but refers to scripts if and when more complex logic is needed. With <a href=""https://github.com/binaryaffairs/a-la-mode"">A La Mode</a>, we're seeing the first open source tool appear in this space.</p>"
Legacy migration feature parity,Hold,Techniques,FALSE,"<p>We find that more and more organizations need to replace aging legacy systems to keep up with the demands of their customers (both internal and external). One antipattern we keep seeing is <strong>legacy migration feature parity</strong> , the desire to retain feature parity with the old. We see this as a huge missed opportunity. Often the old systems have bloated over time, with many features unused by users (50% according to a <a href=""https://www.standishgroup.com/sample_research_files/Exceeding%20Value_Layout.pdf"">2014 Standish Group report</a>) and business processes that have evolved over time. Replacing these features is a waste. Our advice: Convince your customers to take a step back and understand what their users currently <em>need</em> and prioritize these needs against business outcomes and metrics — which often is easier said than done. This means conducting user research and applying modern product development practices rather than simply replacing the existing ones.</p>"
Log aggregation for business analytics,Hold,Techniques,TRUE,"<p>Several years ago, a new generation of log aggregation platforms emerged that were capable of storing and searching over vast amounts of log data to uncover trends and insights in operational data. <a href=""/radar/tools/splunk"">Splunk</a> was the most prominent but by no means the only example of these tools. Because these platforms provide broad operational and security visibility across the entire estate of applications, administrators and developers have grown increasingly dependent on them. This enthusiasm spread as stakeholders discovered that they could use <strong>log aggregation for business analytics</strong>. However, business needs can quickly outstrip the flexibility and usability of these tools. Logs intended for technical observability are often inadequate to infer deep customer understanding. We prefer either to use tools and metrics designed for customer analytics or to take a more event-driven approach to observability where both business and operational events are collected and stored in a way they can be replayed and processed by more purpose-built tools.</p>"
Long-lived branches with Gitflow,Hold,Techniques,FALSE,"<p>Five years ago we highlighted the problems with <strong>long-lived branches with Gitflow</strong>. Essentially, long-lived branches are the opposite of continuously integrating all changes to the source code, and in our experience continuous integration is the better approach for most kinds of software development. Later we extended our caution to <a href=""/radar/techniques/gitflow"">Gitflow</a> itself, because we saw teams using it almost exclusively with long-lived branches. Today, we still see teams in settings where continuous delivery of web-based systems is the stated goal being drawn to long-lived branches. So we were delighted that the author of Gitflow has now added a note to his <a href=""https://nvie.com/posts/a-successful-git-branching-model/"">original article</a>, explaining that Gitflow was not intended for such use cases.</p>"
Istio,Adopt,Platforms,FALSE,"<p>If you're building and operating a scaled <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> architecture and have embraced <a href=""/radar/platforms/kubernetes"">Kubernetes</a>, adopting <a href=""/radar/techniques/service-mesh"">service mesh</a> to manage all cross-cutting aspects of running the architecture is a default position. Among various implementations of service mesh, <strong><a href=""https://istio.io"">Istio</a></strong> has gained majority adoption. It has a rich feature set, including service discovery, traffic management, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency. Its user experience has been improved in its latest releases, because of its ease of installation and control panel architecture. Istio has lowered the bar for implementing large-scale microservices with operational quality for many of our clients, while admitting that operating your own Istio and Kubernetes instances requires adequate knowledge and internal resources which is not for the fainthearted.</p>"
Argo CD,Trial,Platforms,TRUE,"<p>Without making a judgment of the GitOps technique, we'd like to talk about <strong><a href=""https://argoproj.github.io/argo-cd/"">Argo CD</a></strong> within the scope of deploying and monitoring applications in <a href=""/radar/platforms/kubernetes"">Kubernetes</a> environments. Based on its ability to automate the deployment of the desired application state in the specified target environments in Kubernetes and our good experience with troubleshooting failed deployments, verifying logs and monitoring deployment status, we recommend you give Argo CD a try. You can even see graphically what is going on in the cluster, how a change is propagated and how pods are created and destroyed in real time.</p>"
Firebase,Adopt,Platforms,TRUE,"<p>Google's <strong><a href=""https://firebase.google.com/"">Firebase</a></strong> has undergone significant evolution since we mentioned it as part of a <a href=""/radar/techniques/serverless-architecture"">serverless architecture</a> in 2016. Firebase is a comprehensive platform for building mobile and web apps in a way that's supported by Google's underlying scalable infrastructure. We particularly like Firebase App Distribution, which makes it easy to publish test versions of an app via a CD pipeline, and Firebase Remote Config, which allows configuration changes to be dynamically pushed to apps without needing to republish them.</p>"
OpenTelemetry,Trial,Platforms,FALSE,"<p><strong><a href=""https://opentelemetry.io/"">OpenTelemetry</a></strong> is an open source observability project that merges <a href=""https://opentracing.io/"">OpenTracing</a> and <a href=""https://github.com/census-instrumentation"">OpenCensus</a>. The OpenTelemetry project includes <a href=""https://github.com/open-telemetry/opentelemetry-specification"">specification</a>, libraries, agents, and other components needed to capture telemetry from services to better observe, manage and debug them. It covers the three pillars of observability — distributed tracing, metrics and logging (currently in beta) — and its specification connects these three pieces through <a href=""https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/correlationcontext/api.md"">correlations</a>; thus you can use <em>metrics</em> to pinpoint a problem, locate the corresponding <em>traces</em> to discover where the problem occured, and ultimately study the corresponding <em>logs</em> to find the exact root cause. OpenTelemetry components can be connected to back-end observability systems such as <a href=""/radar/tools/prometheus"">Prometheus</a> and <a href=""/radar/tools/jaeger"">Jaeger</a> among <a href=""https://opentelemetry.io/registry/?s=exporter"">others</a>. Formation of OpenTracing is a positive step toward the convergence of standardization and the simplification of tooling.</p>"
Snowflake,Adopt,Platforms,FALSE,"<p><strong><a href=""https://www.snowflake.com"">Snowflake</a></strong> has proven to be a robust SaaS big data storage, warehouse or lake solution for many of our clients. It has a superior architecture to scale storage, compute, and services to load, unload and use data. It's also very flexible: it supports storage of structured, semi-structured and unstructured data; provides a growing list of <a href=""https://docs.snowflake.com/en/user-guide/conns-drivers.html"">connectors</a> for different access patterns such as Spark for data science and SQL for analytics; and runs on multiple cloud providers. Our advice to many of our clients is to use managed services for their utility technology such as big data storage; however, if the risk and regulations prohibit the use of managed services, then Snowflake is a good candidate for companies with large volumes of data and heavy processing workloads. Although we've been successful using Snowflake in our medium-sized engagements, we've yet to experience Snowflake in large ecosystems where data need to be owned across segments of the organization.</p>"
JupyterLab,Assess,Platforms,TRUE,"<p><strong><a href=""https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html"">JupyterLab</a></strong> is the next-generation web-based user interface for Project <a href=""/radar/tools/jupyter"">Jupyter</a>. If you've been using Jupyter Notebooks, JupyterLab is worth a try; it gives you an interactive environment for Jupyter notebooks, code and data. We see it as an evolution of Jupyter Notebook: it provides a better experience by extending its original capabilities of allowing code, visualization and documentation to exist in one place.</p>"
Node overload,Hold,Platforms,TRUE,"<p>Technologies, especially wildly popular ones, have a tendency to be overused. What we're seeing at the moment is <strong>Node overload</strong>, a tendency to use Node.js indiscriminately or for the wrong reasons. Among these, two stand out in our opinion. Firstly, we frequently hear that Node should be used so that all programming can be done in one programming language. Our view remains that <a href=""/radar/techniques/polyglot-programming"">polyglot programming</a> is a better approach, and this still goes <a href=""/radar/languages-and-frameworks/javascript-as-a-first-class-language"">both ways</a>. Secondly, we often hear teams cite performance as a reason to choose Node.js. Although there are myriads of more or less sensible benchmarks, this perception is rooted in history. When Node.js became popular, it was the first major framework to embrace a nonblocking programming model which made it very efficient for IO-heavy tasks. (We mentioned this in our write-up of Node.js in 2012.) Due to its single-threaded nature, Node.js was never a good choice for compute-heavy workloads, though, and now that capable nonblocking frameworks also exist on other platforms — some with elegant, modern APIs — performance is no longer a reason to choose Node.js.</p>"
Cloudwatch Insights,Adopt,Tools,TRUE,Go to log aggregation analysis tool for structured logging
Secrets Manager,Adopt,Tools,TRUE,
Phrase,Trial,Tools,TRUE,"<p>As mentioned in our description of <a href=""/radar/platforms/crowdin"">Crowdin</a>, you now have a choice of platforms to manage the translation of a product into multiple languages instead of emailing large spreadsheets. Our teams report positive experiences with <strong><a href=""https://phrase.com/"">Phrase</a></strong>, emphasizing that it's easy to use for all key user groups. Translators use a convenient browser-based UI. Managers can add new fields and synchronize translations with other teams in the same UI. Developers can access Phrase locally and from a build pipeline. A feature that deserves a specific mention is the ability to apply versioning to translations through tags, which makes it possible to compare the look of different translations inside the actual product.</p>"
Visual Studio Live Share,Trial,Tools,FALSE,"<p><strong><a href=""https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare-pack"">Visual Studio Live Share</a></strong> is a suite of extensions for <a href=""/radar/tools/visual-studio-code"">Visual Studio Code</a> and Visual Studio. At a time when teams are searching for good remote collaboration options, we want to call attention to the excellent tooling here. Live Share provides a good, low-latency remote-pairing experience, and requires significantly less bandwidth than the brute-force approach of sharing your entire desktop. Importantly, developers can work with their preferred configuration, extensions and key mappings during a pairing session. In addition to real-time collaboration for editing and debugging code, Live Share allows voice calls and sharing terminals and servers.</p>"
AsyncAPI,Assess,Tools,TRUE,"<p>Open standards are one of the foundational pillars of building distributed systems. For example, the <a href=""https://github.com/OAI"">OpenAPI (formerly Swagger)</a> specification, as an industry standard to define RESTful APIs, has been instrumental to the success of distributed architectures such as <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>. It has enabled a proliferation of tooling to support building, testing and monitoring RESTful APIs. However, such standardizations have been largely missing in distributed systems for <a href=""https://martinfowler.com/articles/201701-event-driven.html"">event-driven APIs</a>.</p>

<p><strong><a href=""https://www.asyncapi.com/"">AsyncAPI</a></strong> is an open source initiative to create a much needed event-driven and asynchronous API standardization and development tooling. The <a href=""https://www.asyncapi.com/docs/specifications/2.0.0/"">AsyncAPI specification</a>, inspired by the OpenAPI specification, describes and documents event-driven APIs in a machine-readable format. It's protocol agnostic, so it can be used for APIs that work over many protocols, including MQTT, WebSockets, and Kafka. We're eager to see the ongoing improvements of AsyncAPI and further maturity of its tooling ecosystem.</p>"
Chamber,Hold,Tools,FALSE,"Chamber is a good tool for listing secrets stored in SSM, but numerous bugs related to case sensitivity have caused us to re-evaluate it's use and can no longer recommend it"
AWS Parameter Store (SSM),Hold,Tools,FALSE,Secrets Manager is just a better tool in every way
React Hooks,Adopt,languages-and-frameworks,FALSE,"<p><strong><a href=""https://reactjs.org/docs/hooks-intro.html"">React Hooks</a></strong> have introduced a new approach to managing stateful logic; given React components have always been closer to functions than classes, Hooks have embraced this and brought state to the functions, instead of taking function as methods to the state with classes. Based on our experience, Hooks improve reuse of functionality among components and code readability. Given Hooks’ testability improvements, using <a href=""https://reactjs.org/docs/test-renderer.html"">React Test Renderer</a> and <a href=""/radar/languages-and-frameworks/react-testing-library"">React Testing Library</a>, and their growing community support, we consider them our approach of choice.</p>"
Ruby On Rails,Adopt,languages-and-frameworks,FALSE,
Flask,Adopt,languages-and-frameworks,FALSE,"<p><strong><a href=""https://flask.palletsprojects.com/en/1.1.x/"">Flask</a></strong> is a micro framework for python services. This ""micro"" refers to the core of the framework, and it can be combined with extensions for projects from micro services to full web apps.</p>"
Gin,Trial,languages-and-frameworks,FALSE,"<p><strong><a href=""https://github.com/gin-gonic/gin"">Gin</a></strong> s a web framework written in Go (Golang). It features a martini-like API with performance that is up to 40 times faster thanks to <a href=""https://github.com/julienschmidt/httprouter"">httprouter</a>. If you need performance and good productivity, you will love Gin.</p>"
HapiJS,Hold,languages-and-frameworks,FALSE,"<p><strong><a href=""https://github.com/hapijs/hapi"">hapi<a></strong> is a node framework with the occassional Ren & Stimpy reference. But like the TV show, it has come to an end</p>"
Vue.js,Trial,languages-and-frameworks,TRUE,"<p><strong><a href=""https://vuejs.org/"">Vue.js</a></strong> has become one of the successfully applied, loved and trusted frontend JavaScript frameworks among our community. Although there are other, well-adopted alternatives, such as <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>, the simplicity of Vue.js in API design, its clear segregation of directives and components (one file per component idiom) and its simpler state management have made it a compelling option among others.</p>"
PyTorch,Trial,languages-and-frameworks,TRUE,"<p>Our teams have continued to use and appreciate the <strong><a href=""http://pytorch.org/"">PyTorch</a></strong> machine learning framework, and several teams prefer PyTorch over <a href=""/radar/languages-and-frameworks/tensorflow"">TensorFlow</a>. PyTorch exposes the inner workings of ML that TensorFlow hides, making it easier to debug, and contains constructs that programmers are familiar with such as loops and actions. Recent releases have improved performance of PyTorch, and we've been using it successfully in production projects.</p>"
Rust,Assess,languages-and-frameworks,TRUE,"<p><strong><a href=""http://www.rust-lang.org/"">Rust</a></strong> is continuously gaining in popularity. We've had heated discussions about which is better, Rust or C++/Go, without a clear winner. However, we're glad to see Rust has improved significantly, with more built-in APIs being added and stabilized, including <a href=""https://blog.rust-lang.org/2019/11/07/Async-await-stable.html"">advanced async support</a>, since we mentioned it in our previous Radar. In addition, Rust has also inspired the design of new languages. For example, the <a href=""https://developers.libra.org/docs/move-overview"">Move language</a> on Libra borrows Rust's way of managing memory to manage resources, ensuring that digital assets can never be copied or implicitly discarded.</p>"
AngularJs,Hold,languages-and-frameworks,FALSE,No need to say anything
Angular,Hold,languages-and-frameworks,FALSE,
DataOps,Trial,Techniques,TRUE,"<p><strong><a href="https://www.dataopsmanifesto.org/">DataOps</a></strong> is an automated, process-oriented methodology, used by analytic and data teams, to improve the quality and reduce the cycle time of data analytics. The DataOps manifesto defines a set of organizing principles for teams to follow.</p>"
Airflow,Trial,Tools,TRUE,"<p><strong><a href="https://airflow.apache.org/">Airflow</a></strong> is an open-source workflow management platform to programmatically author and schedule data pipeline workflows.</p>"
DBT,Assess,Tools,TRUE,"<p><strong><a href="https://docs.getdbt.com/">DBT</a></strong> is a data transformation tool that enables data engineers to transform data in data pipeline jobs using just SQL.</p>"
Argo Workflows,Assess,Tools,TRUE,"<p><strong><a href="https://argoproj.github.io/docs/argo/readme.html">Argo Workflows</a></strong> is a workflow management platform that integrates natively with Kubernetes and allows engineers to declaritively define data pipelines.</p>"
Debezium,Assess,Tools,TRUE,"<p><strong><a href="https://debezium.io/">Debezium</a></strong> is a Change Data Capture tool for streaming changes from a source database with low latency.</p>"
Looker,Hold,Tools,FALSE,"<p><strong><a href="https://looker.com/">Looker</a></strong> is a business intelligence software and big data analytics platform that is our primary reporting and analytics tool.</p>"
Treasure Data,Hold,Tools,FALSE,"<p><strong><a href="">Treasure Data</a></strong> is a platform for building and managing data pipelines. It is being replaced by a combination of Snowflake+Airflow+DBT.</p>"